{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EmotionModel.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPbx0dpujFgXvOT9YPd7bHT"},"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.5"},"interpreter":{"hash":"4e0e75d05d039dd9ca5f52480d7ea6246359503b2e9474290afe8ad5a4d90f21"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jaLxBPZtkQCM"},"source":["**Trouble Shooting List**\n","\n","[Kaggle-Competitions::Facial Expression Recognition(FER)Challenge](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data?select=fer2013.tar.gz)\n","\n","[Kaggle-Datasets::Facial Expression Recognition(FER)Challenge](https://www.kaggle.com/ashishpatel26/facial-expression-recognitionferchallenge)\n","\n","[Easiest way to download kaggle data in Google Colab](https://www.kaggle.com/general/74235)\n","\n","[Download kaggle dataset to PC](https://medium.com/@ankushchoubey/how-to-download-dataset-from-kaggle-7f700d7f9198)\n","\n","** 語意問題 **\n","\n","[Q1]- What is df'.unique' ?\n","\n","[Q2]- What is math.sqrt used for?\n","\n","[Q3]- 'df .isin'?\n","\n","[Q4]- [what-are-lamda-funcs](https://www.analyticsvidhya.com/blog/2020/03/what-are-lambda-functions-in-python/)\n","\n","** 主要參考 **\n","\n","[Refernce Submissions](https://www.kaggle.com/gauravsharma99/facial-emotion-recognition)"]},{"cell_type":"code","metadata":{"id":"bsQCp6m9dAsw","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1625503597450,"user_tz":-480,"elapsed":12433,"user":{"displayName":"曹廷群","photoUrl":"","userId":"18315656931537193746"}},"outputId":"182a372f-3231-46dd-99e7-b164379f97f6"},"source":["# download kaggle dataset to google colab\n","! pip install -q kaggle\n","from google.colab import files\n","files.upload()\n","! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json\n","! kaggle datasets list\n","! kaggle competitions download -c 'challenges-in-representation-learning-facial-expression-recognition-challenge'"],"execution_count":null,"outputs":[]},{"source":["** download datasets from kaggle to PC**\n","\n","check more at [link](https://dccheng.medium.com/296e7916ba91), [reference link](https://www.kaggle.com/gauravsharma99/facial-emotion-recognition)"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","for dirname, _, filenames in os.walk('/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","\n","import scikitplot\n","import seaborn as sns\n","from matplotlib import pyplot\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report\n","\n","import tensorflow as tf\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from keras.utils import np_utils"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('../input/fer2013/fer2013.csv')\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.emotion.unique() #[Q1]\n","emotion_label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}\n","df.emotion.value_counts()\n","sns.countplot(df.emotion)\n","pyplot.show()"]},{"source":["Majority classes belongs to \n","3: Happy\n","4: Sad\n","6: Neutral\n","These three nd classes that we are interested in."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["math.sqrt(len(df.pixels[0].split(' '))) #[Q2]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# draw datasets fig\n","fig = pyplot.figure(1, (14, 14))\n","\n","k = 0\n","for label in sorted(df.emotion.unique()):\n","    for j in range(7):\n","        px = df[df.emotion==label].pixels.iloc[k]\n","        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n","\n","        k += 1\n","        ax = pyplot.subplot(7, 7, k)\n","        ax.imshow(px, cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(emotion_label_to_text[label])\n","        pyplot.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["INTERESTED_LABELS = [3, 4, 6]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df[df.emotion.isin(INTERESTED_LABELS)] #[Q3]\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create datasets\n","img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48, 1).astype('float32'))#[Q4]\n","img_array = np.stack(img_array, axis=0)\n","img_array.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["le = LabelEncoder()\n","img_labels = le.fit_transform(df.emotion)\n","img_labels = np_utils.to_categorical(img_labels)\n","img_labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n","print(le_name_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train-split\n","X_train, X_valid, y_train, y_valid = train_test_split(img_array, img_labels,\n","                                                    shuffle=True, stratify=img_labels,\n","                                                    test_size=0.1, random_state=42)\n","                                                    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del df\n","del img_array\n","del img_labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_width = X_train.shape[1]\n","img_height = X_train.shape[2]\n","img_depth = X_train.shape[3]\n","num_classes = y_train.shape[1]\n","print(X_train.shape)\n","print(y_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Normalized\n","X_train = X_train / 255.\n","X_valid = X_valid / 255."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_net(optim):\n","    \"\"\"\n","    This is a Deep Convolutional Neural Network (DCNN). For generalization purpose I used dropouts in regular intervals.\n","    I used `ELU` as the activation because it avoids dying relu problem but also performed well as compared to LeakyRelu\n","    atleast in this case. `he_normal` kernel initializer is used as it suits ELU. BatchNormalization is also used for better\n","    results.\n","    \"\"\"\n","    net = Sequential(name='DCNN')\n","\n","    net.add(\n","        Conv2D(\n","            filters=64,\n","            kernel_size=(5,5),\n","            input_shape=(img_width, img_height, img_depth),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal',\n","            name='conv2d_1'\n","        )\n","    )\n","    net.add(BatchNormalization(name='batchnorm_1'))\n","    net.add(\n","        Conv2D(\n","            filters=64,\n","            kernel_size=(5,5),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal',\n","            name='conv2d_2'\n","        )\n","    )\n","    net.add(BatchNormalization(name='batchnorm_2'))\n","    \n","    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n","    net.add(Dropout(0.4, name='dropout_1'))\n","\n","    net.add(\n","        Conv2D(\n","            filters=128,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal',\n","            name='conv2d_3'\n","        )\n","    )\n","    net.add(BatchNormalization(name='batchnorm_3'))\n","    net.add(\n","        Conv2D(\n","            filters=128,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal',\n","            name='conv2d_4'\n","        )\n","    )\n","    net.add(BatchNormalization(name='batchnorm_4'))\n","    \n","    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n","    net.add(Dropout(0.4, name='dropout_2'))\n","\n","    net.add(\n","        Conv2D(\n","            filters=256,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal',\n","            name='conv2d_5'\n","        )\n","    )\n","    net.add(BatchNormalization(name='batchnorm_5'))\n","    net.add(\n","        Conv2D(\n","            filters=256,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal',\n","            name='conv2d_6'\n","        )\n","    )\n","    net.add(BatchNormalization(name='batchnorm_6'))\n","    \n","    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n","    net.add(Dropout(0.5, name='dropout_3'))\n","\n","    net.add(Flatten(name='flatten'))\n","        \n","    net.add(\n","        Dense(\n","            128,\n","            activation='elu',\n","            kernel_initializer='he_normal',\n","            name='dense_1'\n","        )\n","    )\n","    net.add(BatchNormalization(name='batchnorm_7'))\n","    \n","    net.add(Dropout(0.6, name='dropout_4'))\n","    \n","    net.add(\n","        Dense(\n","            num_classes,\n","            activation='softmax',\n","            name='out_layer'\n","        )\n","    )\n","    \n","    net.compile(\n","        loss='categorical_crossentropy',\n","        optimizer=optim,\n","        metrics=['accuracy']\n","    )\n","    \n","    net.summary()\n","    \n","    return net"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create two callbacks\n","\"\"\" \n","    1. eraly_stopping: avoid overfitting the training data\n","    2. lr_scheduler: using ReduceLROnPlateau for learning rate\n","\"\"\"\n","early_stopping = EarlyStopping(\n","    monitor='val_accuracy',\n","    min_delta=0.00005,\n","    patience=11,\n","    verbose=1,\n","    restore_best_weights=True,\n",")\n","\n","lr_scheduler = ReduceLROnPlateau(\n","    monitor='val_accuracy',\n","    factor=0.5,\n","    patience=7,\n","    min_lr=1e-7,\n","    verbose=1,\n",")\n","\n","callbacks = [\n","    early_stopping,\n","    lr_scheduler,\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# image data genertor\n","train_datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.15,\n","    height_shift_range=0.15,\n","    shear_range=0.15,\n","    zoom_range=0.15,\n","    horizontal_flip=True,\n",")\n","train_datagen.fit(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#parameter settings\n","batch_size = 32 #batch size of 32 performs the best.\n","epochs = 100\n","optims = [\n","    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n","    optimizers.Adam(0.001),\n","]"]},{"source":["# start training: model and history\n","\"\"\"\n","    optional models(optims[n]))\n","\"\"\"\n","\n","model = build_net(optims[1])\n","# model = build_net(optims[2])\n"],"cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"error","ename":"UnknownError","evalue":" Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node DCNN/conv2d_1/Conv2D (defined at <ipython-input-23-be7303451f26>:1) ]] [Op:__inference_train_function_3387]\n\nFunction call stack:\ntrain_function\n","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m<ipython-input-23-be7303451f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(X_train,y_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node DCNN/conv2d_1/Conv2D (defined at <ipython-input-23-be7303451f26>:1) ]] [Op:__inference_train_function_3387]\n\nFunction call stack:\ntrain_function\n"]}],"source":["\n","history = model.fit(X_train,y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    callbacks=callbacks,\n","                    validation_data=(X_valid, y_valid))\n","\n","\"\"\"\n","history = model.fit_generator(\n","    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n","    validation_data=(X_valid, y_valid),\n","    steps_per_epoch=len(X_train) / batch_size,\n","    epochs=epochs,\n","    callbacks=callbacks,\n","    # use_multiprocessing=True\n","    use_multiprocessing=False\n",")\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save model\n","model_yaml = model.to_yaml()\n","with open(\"model.yaml\", \"w\") as yaml_file:\n","    yaml_file.write(model_yaml)\n","    \n","model.save(\"model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot loss\n","sns.set()\n","fig = pyplot.figure(0, (12, 4))\n","\n","ax = pyplot.subplot(1, 2, 1)\n","sns.lineplot(history.epoch, history.history['accuracy'], label='train')\n","sns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\n","pyplot.title('Accuracy')\n","pyplot.tight_layout()\n","\n","ax = pyplot.subplot(1, 2, 2)\n","sns.lineplot(history.epoch, history.history['loss'], label='train')\n","sns.lineplot(history.epoch, history.history['val_loss'], label='valid')\n","pyplot.title('Loss')\n","pyplot.tight_layout()\n","\n","pyplot.savefig('epoch_history_dcnn.png')\n","pyplot.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot performance\n","df_accu = pd.DataFrame({'train': history.history['accuracy'], 'valid': history.history['val_accuracy']})\n","df_loss = pd.DataFrame({'train': history.history['loss'], 'valid': history.history['val_loss']})\n","\n","fig = pyplot.figure(0, (14, 4))\n","ax = pyplot.subplot(1, 2, 1)\n","sns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_accu), showfliers=False)\n","pyplot.title('Accuracy')\n","pyplot.tight_layout()\n","\n","ax = pyplot.subplot(1, 2, 2)\n","sns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_loss), showfliers=False)\n","pyplot.title('Loss')\n","pyplot.tight_layout()\n","\n","pyplot.savefig('performance_dist.png')\n","pyplot.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot in confusion matrix\n","yhat_valid = model.predict_classes(X_valid)\n","scikitplot.metrics.plot_confusion_matrix(np.argmax(y_valid, axis=1), yhat_valid, figsize=(7,7))\n","pyplot.savefig(\"confusion_matrix_dcnn.png\")\n","\n","print(f'total wrong validation predictions: {np.sum(np.argmax(y_valid, axis=1) != yhat_valid)}\\n\\n')\n","print(classification_report(np.argmax(y_valid, axis=1), yhat_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mapper = {\n","    0: \"happy\",\n","    1: \"sad\",\n","    2: \"neutral\",\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot in map\n","np.random.seed(2)\n","random_sad_imgs = np.random.choice(np.where(y_valid[:, 1]==1)[0], size=9)\n","random_neutral_imgs = np.random.choice(np.where(y_valid[:, 2]==1)[0], size=9)\n","\n","fig = pyplot.figure(1, (18, 4))\n","\n","for i, (sadidx, neuidx) in enumerate(zip(random_sad_imgs, random_neutral_imgs)):\n","        ax = pyplot.subplot(2, 9, i+1)\n","        sample_img = X_valid[sadidx,:,:,0]\n","        ax.imshow(sample_img, cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(f\"true:sad, pred:{mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n","\n","        ax = pyplot.subplot(2, 9, i+10)\n","        sample_img = X_valid[neuidx,:,:,0]\n","        ax.imshow(sample_img, cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(f\"t:neut, p:{mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n","\n","        pyplot.tight_layout()"]}]}